{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSYwDHfU8Zfh"
      },
      "source": [
        "#**Import** **necessary** **packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkdPbKF_ZmMl"
      },
      "source": [
        "!pip install livelossplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZVq9uz6nFjK"
      },
      "source": [
        "import random\n",
        "\n",
        "random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlW0GEz88ZCu"
      },
      "source": [
        "from livelossplot import PlotLossesKeras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "\n",
        "\n",
        "# Make numpy printouts easier to read.\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owZUWvLH8lMo"
      },
      "source": [
        "#**Import dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izq7RASC8rYO"
      },
      "source": [
        "data = pd.read_excel('/content/new.xlsx')\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLD6t8ttuUC7"
      },
      "source": [
        "dataset = data.sample(frac=1)\n",
        "dataset\n",
        "#dataset.to_excel('sample.xls')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Po0Axk886k_"
      },
      "source": [
        "#**Clean the dataset (CL)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiHAAKFxIyhc"
      },
      "source": [
        "dataset = data[['Length','Breadth', 'Draft', 'LDT', 'GRT', 'NRT', 'BHP']].copy()\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEVfU3cp9H7m"
      },
      "source": [
        "dataset.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLd7I2yX6phl"
      },
      "source": [
        "dataset.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "xm1Sit8k7v1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boWLyZAd9Z2q"
      },
      "source": [
        "#**Inspect the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "W.r.t Length"
      ],
      "metadata": {
        "id": "coWSde0AJ5tD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvBQbijMHfF5"
      },
      "source": [
        "%matplotlib inline\n",
        "plt.xlabel('Length(L) m')\n",
        "plt.ylabel('LDT')\n",
        "plt.scatter(dataset.Length, dataset.LDT,color='red',marker='+')\n",
        "plt.show()\n",
        "\n",
        "plt.xlabel('Length(L) m')\n",
        "plt.ylabel('GRT')\n",
        "plt.scatter(dataset.Length, dataset.GRT,color='blue',marker='+')\n",
        "plt.show()\n",
        "\n",
        "plt.xlabel('Length(L) m')\n",
        "plt.ylabel('BHP')\n",
        "plt.scatter(dataset.Length, dataset.BHP,color='black',marker='+')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "W.r.t Breadth"
      ],
      "metadata": {
        "id": "BnHP2C0IJ-xW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "plt.xlabel('Breadth(B) m')\n",
        "plt.ylabel('LDT')\n",
        "plt.scatter(dataset.Breadth, dataset.LDT,color='red',marker='+')\n",
        "plt.show()\n",
        "\n",
        "plt.xlabel('Breadth(B) m')\n",
        "plt.ylabel('GRT')\n",
        "plt.scatter(dataset.Breadth, dataset.GRT,color='blue',marker='+')\n",
        "plt.show()\n",
        "\n",
        "plt.xlabel('Breadth(B) m')\n",
        "plt.ylabel('BHP')\n",
        "plt.scatter(dataset.Breadth, dataset.BHP,color='black',marker='+')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "11ScBZC_KAuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "W.r.t Depth"
      ],
      "metadata": {
        "id": "6bI3n5arKNTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "plt.xlabel('Draft(d) m')\n",
        "plt.ylabel('LDT')\n",
        "plt.scatter(dataset.Draft, dataset.LDT,color='red',marker='+')\n",
        "plt.show()\n",
        "\n",
        "plt.xlabel('Draft(d) m')\n",
        "plt.ylabel('GRT')\n",
        "plt.scatter(dataset.Draft, dataset.GRT,color='blue',marker='+')\n",
        "plt.show()\n",
        "\n",
        "plt.xlabel('Draft(d) m')\n",
        "plt.ylabel('BHP')\n",
        "plt.scatter(dataset.Draft, dataset.BHP,color='black',marker='+')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Zqubw787KQWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bt0RyyQiZmGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Split the data into train and test**"
      ],
      "metadata": {
        "id": "ztoe_paf9vBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset.sample(frac=0.9, random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)"
      ],
      "metadata": {
        "id": "U3-vYdef9xfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQaAVyaP9hGc"
      },
      "source": [
        "#**Split features from labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SwLS1x-VGvE"
      },
      "source": [
        "train_features = train_dataset.iloc[:,0:3]\n",
        "train_labels = train_dataset.iloc[:,3:]\n",
        "\n",
        "test_features = test_dataset.iloc[:,0:3]\n",
        "test_labels = test_dataset.iloc[:,3:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unTwtjbL9mVE"
      },
      "source": [
        "#**Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlC5ooJrgjQF"
      },
      "source": [
        "normalizer = preprocessing.Normalization(axis=1)\n",
        "normalizer.adapt(np.array(train_features))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA"
      ],
      "metadata": {
        "id": "dWWx-mkQZq6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "x = StandardScaler().fit_transform(train_features)\n",
        "\n",
        "PCApca = PCA(n_components=3)\n",
        "principalComponents = pca.fit_transform(x)\n",
        "principalDf = pd.DataFrame(data = principalComponents\n",
        "             , columns = ['principal component 1', 'principal component 2', 'principal component 3'])"
      ],
      "metadata": {
        "id": "tsgX32t-ZsNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "principalDf"
      ],
      "metadata": {
        "id": "BABNjtdhaDr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finalDf = pd.concat([principalDf, test_labels], axis = 1)"
      ],
      "metadata": {
        "id": "nTWobXohbGpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finalDf"
      ],
      "metadata": {
        "id": "9ev3UXQqbZ2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize = (8,8))\n",
        "ax = fig.add_subplot(1,1,1) \n",
        "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
        "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
        "ax.set_title('2 component PCA', fontsize = 20)targets = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
        "colors = ['r', 'g', 'b']\n",
        "for target, color in zip(targets,colors):\n",
        "    indicesToKeep = finalDf['target'] == target\n",
        "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
        "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
        "               , c = color\n",
        "               , s = 50)\n",
        "ax.legend(targets)\n",
        "ax.grid()"
      ],
      "metadata": {
        "id": "0bE1W-GEa9KR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GhuHSE4MMwq"
      },
      "source": [
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4Xd82bGZiz_"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# linear regression for multioutput regression\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "train_features, train_labels = make_regression(n_samples=1000, n_features=3, n_informative=5, n_targets=1, random_state=1, noise=0.5)\n",
        "model = LinearRegression()\n",
        "model.fit(train_features, train_labels)\n",
        "yhat = model.predict(test_features)\n",
        "print(yhat)"
      ],
      "metadata": {
        "id": "W7m8ny7pM3mN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels"
      ],
      "metadata": {
        "id": "AacxE9eLYexv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = model.predict(test_features)\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values')\n",
        "plt.ylabel('Predictions')\n",
        "limX = [0, 160000]\n",
        "limY = [0, 35000]\n",
        "plt.xlim(limX)\n",
        "plt.ylim(limY)\n",
        "_ = plt.plot(limX, limY)\n"
      ],
      "metadata": {
        "id": "j1uDOcqkNop5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "coefficient_of_dermination = r2_score(test_labels, test_predictions)\n",
        "coefficient_of_dermination"
      ],
      "metadata": {
        "id": "Rk909s1pNy1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxODwOZeMFDN"
      },
      "source": [
        " # **Linear Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FJgdZ90MS2A"
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "train_features, train_labels = make_regression(n_samples=1000, n_features=3, n_informative=5, n_targets=4, random_state=1, noise=0.5)\n",
        "model_2 = KNeighborsRegressor()\n",
        "model_2.fit(train_features, train_labels)\n",
        "yhat = model_2.predict(test_features)\n",
        "print(yhat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = model_2.predict(test_features)\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values')\n",
        "plt.ylabel('Predictions')\n",
        "limX = [0, 160000]\n",
        "limY = [0, 35000]\n",
        "plt.xlim(limX)\n",
        "plt.ylim(limY)\n",
        "_ = plt.plot(limX, limY)\n"
      ],
      "metadata": {
        "id": "a6KbAMxWRb9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hjh57XWYMixq"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "coefficient_of_dermination = r2_score(test_labels, yhat)\n",
        "coefficient_of_dermination"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvAbA_e3JvzS"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KunRnpfJtir"
      },
      "source": [
        "# evaluate multioutput regression model with k-fold cross-validation\n",
        "from numpy import absolute\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "\n",
        "train_features, train_labels = make_regression(n_samples=1000, n_features=3, n_informative=5, n_targets=4, random_state=1, noise=0.5)\n",
        "model_2 = KNeighborsRegressor()\n",
        "model_2.fit(train_features, train_labels)\n",
        "yhat = model_2.predict(test_features)\n",
        "print(yhat)\n",
        "\n",
        "# create datasets\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
        "# define model\n",
        "model = DecisionTreeRegressor()\n",
        "# define the evaluation procedure\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate the model and collect the scores\n",
        "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
        "# force the scores to be positive\n",
        "n_scores = absolute(n_scores)\n",
        "# summarize performance\n",
        "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6LXnhHBMoEs"
      },
      "source": [
        "%%time\n",
        "history = linear_model.fit(\n",
        "    train_features, train_labels, \n",
        "    epochs=100,\n",
        "    # suppress logging\n",
        "    verbose=1,\n",
        "    callbacks=[PlotLossesKeras()],\n",
        "    # Calculate validation results on 20% of the training data\n",
        "    validation_split = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjP8LVPmNE-c"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.ylim([0, 0.9])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Error')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SDa7R57N7_s"
      },
      "source": [
        "loss_df = pd.DataFrame(history.history[\"loss\"])\n",
        "loss_df.columns =['Linear']\n",
        "loss_df.to_excel('Linear.xls')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PX4TRYGOGee"
      },
      "source": [
        "val_loss_df = pd.DataFrame(history.history[\"val_loss\"])\n",
        "val_loss_df.columns =['Linear']\n",
        "val_loss_df.to_excel('val_Linear.xls')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPg_tevuMxtL"
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRu48iFtNZYS"
      },
      "source": [
        "test_results = {}\n",
        "\n",
        "test_results['linear_model'] = linear_model.evaluate(\n",
        "    test_features, test_labels, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZKJCeiUNm0F"
      },
      "source": [
        "pd.DataFrame(test_results, index=['RMSE']).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4ZgeZRd9-tT"
      },
      "source": [
        "#**Model 1**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
      ],
      "metadata": {
        "id": "QZUvdz2kWyDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrNglwggSh5H"
      },
      "source": [
        "def model_1(norm):\n",
        "  model = keras.Sequential([\n",
        "      norm,\n",
        "      layers.Dense(80, activation='relu'),\n",
        "\n",
        "      layers.Dense(80, activation='relu'),\n",
        "\n",
        "      layers.Dense(80, activation='relu'),\n",
        "\n",
        "      layers.Dense(80, activation='relu'),\n",
        "      layers.Dense(80, activation='relu'),\n",
        "      layers.Dense(80, activation='relu'),\n",
        " \n",
        "      layers.Dense(4)])\n",
        "\n",
        "  # model.compile(loss='mean_squared_error',\n",
        "  #               optimizer=tf.keras.optimizers.Adam(0.001))\n",
        "  \n",
        "  model.compile(optimizer = \"rmsprop\", loss = root_mean_squared_error)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0mhscXh2k36"
      },
      "source": [
        "#dnn_model = build_and_compile_model(normalizer)\n",
        "\n",
        "dnn_model_1 = model_1(normalizer)\n",
        "dnn_model_1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXDENACl2tuW"
      },
      "source": [
        "%%time\n",
        "history = dnn_model_1.fit(\n",
        "    train_features, train_labels,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[PlotLossesKeras()],\n",
        "    verbose=1, epochs=400, batch_size = 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0y85uvwJpOT"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.ylim([0, 20000])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Error')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLl3kGqdT-bv"
      },
      "source": [
        "\n",
        "loss_df = pd.DataFrame(history.history[\"loss\"])\n",
        "loss_df.columns =['Model 1']\n",
        "loss_df.to_excel('Model_1.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfLOaxzds3T7"
      },
      "source": [
        "val_loss_df = pd.DataFrame(history.history[\"val_loss\"])\n",
        "val_loss_df.columns =['Model 1']\n",
        "val_loss_df.to_excel('val_Model_1.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9Dbj0fX23RQ"
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWoVYS34fJPZ"
      },
      "source": [
        "Collect the results on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe7RXH3N3CWU"
      },
      "source": [
        "test_predictions = dnn_model_1.predict(test_features)\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values')\n",
        "plt.ylabel('Predictions')\n",
        "lims = [0, 190000]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "coefficient_of_dermination = r2_score(test_labels, test_predictions)\n",
        "coefficient_of_dermination"
      ],
      "metadata": {
        "id": "UqODWmmkDnk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-WwLlmfT-mb"
      },
      "source": [
        "dnn_model_1.save('dnn_model_1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyyyj2zVT-mf"
      },
      "source": [
        "#reloaded = tf.keras.models.load_model('dnn_model_1')\n",
        "\n",
        "test_results = {}\n",
        "\n",
        "test_results['Model 1'] = dnn_model_1.evaluate(test_features, test_labels, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_GchJ2tg-2o"
      },
      "source": [
        "pd.DataFrame(test_results, index=['RMSE']).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBSvjsZdOCIM"
      },
      "source": [
        "#**Model 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2g4y3jdOHOA"
      },
      "source": [
        "def model_2(norm):\n",
        "  model = keras.Sequential([\n",
        "      norm,\n",
        "      layers.Dense(128, activation='relu'),\n",
        "\n",
        "      layers.Dense(128, activation='relu'),\n",
        "\n",
        "      layers.Dense(128, activation='relu'),\n",
        "\n",
        "      layers.Dense(128, activation='relu'),\n",
        "      layers.Dense(128, activation='relu'),\n",
        "      layers.Dense(128, activation='relu'),\n",
        "\n",
        "      layers.Dense(1)])\n",
        "\n",
        "  # model.compile(loss='mean_squared_error',\n",
        "  #               optimizer=tf.keras.optimizers.Adam(0.001))\n",
        "  \n",
        "  model.compile(optimizer = \"rmsprop\", loss = root_mean_squared_error)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TB1ZkMtOHdc"
      },
      "source": [
        "#dnn_model = build_and_compile_model(normalizer)\n",
        "\n",
        "dnn_model_2 = model_2(normalizer)\n",
        "dnn_model_2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnkjOBPGOHp0"
      },
      "source": [
        "%%time\n",
        "history = dnn_model_2.fit(\n",
        "    train_features, train_labels,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[PlotLossesKeras()],\n",
        "    verbose=1, epochs=400, batch_size = 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXZKOtwxOHti"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.ylim([0, 0.4])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('RMSE')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlXTBcwcXfOa"
      },
      "source": [
        "loss_df = pd.DataFrame(history.history[\"loss\"])\n",
        "loss_df.columns =['Model 2']\n",
        "loss_df.to_excel('Model_2.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoXkzPq_tApU"
      },
      "source": [
        "val_loss_df = pd.DataFrame(history.history[\"val_loss\"])\n",
        "val_loss_df.columns =['Model 2']\n",
        "val_loss_df.to_excel('val_Model_2.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4P5PvRaOZRh"
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_O3aJFZOcd5"
      },
      "source": [
        "test_predictions = dnn_model_2.predict(test_features).flatten()\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values')\n",
        "plt.ylabel('Predictions')\n",
        "lims = [0, 2]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCa3MAedOgAc"
      },
      "source": [
        "# error = test_predictions - test_labels\n",
        "# plt.hist(error, bins=25)\n",
        "# plt.xlabel('Prediction Error')\n",
        "# _ = plt.ylabel('Count')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8Ya3DhDOjTX"
      },
      "source": [
        "dnn_model_2.save('dnn_model_2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_ohuW4sOmZz"
      },
      "source": [
        "# reloaded = tf.keras.models.load_model('dnn_model_2')\n",
        "\n",
        "\n",
        "test_results['Model 2'] = dnn_model_2.evaluate(test_features, test_labels, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkxX_LqROp9_"
      },
      "source": [
        "pd.DataFrame(test_results, index=['RMSE']).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO0GGNAtF9j5"
      },
      "source": [
        "# **Model 3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjB8tMCZGHMB"
      },
      "source": [
        "def model_3(norm):\n",
        "  model = keras.Sequential([\n",
        "      norm,\n",
        "      layers.Dense(64, activation='relu'),\n",
        "\n",
        "      layers.Dense(64, activation='relu'),\n",
        "\n",
        "      layers.Dense(64, activation='relu'),\n",
        "\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(64, activation='relu'),\n",
        " \n",
        "      layers.Dense(1)])\n",
        "\n",
        "  # model.compile(loss='mean_squared_error',\n",
        "  #               optimizer=tf.keras.optimizers.Adam(0.001))\n",
        "  \n",
        "  model.compile(optimizer = \"rmsprop\", loss = root_mean_squared_error)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE6DcDVlGHPi"
      },
      "source": [
        "#dnn_model = build_and_compile_model(normalizer)\n",
        "\n",
        "dnn_model_3 = model_3(normalizer)\n",
        "dnn_model_3.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRvv63MZGHSY"
      },
      "source": [
        "%%time\n",
        "history = dnn_model_3.fit(\n",
        "    train_features, train_labels,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[PlotLossesKeras()],\n",
        "    verbose=1, epochs=300, batch_size = 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bcKvye_GHVa"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.ylim([0, 0.3])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('RMSE')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE1Y3ruddna7"
      },
      "source": [
        "loss_df = pd.DataFrame(history.history[\"loss\"])\n",
        "loss_df.columns =['Model 3']\n",
        "loss_df.to_excel('Model_3.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNlyFthmtEVp"
      },
      "source": [
        "val_loss_df = pd.DataFrame(history.history[\"val_loss\"])\n",
        "val_loss_df.columns =['Model 3']\n",
        "val_loss_df.to_excel('val_Model_3.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSbNzsS9GHYH"
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy1fcpO5GHas"
      },
      "source": [
        "test_predictions = dnn_model_3.predict(test_features).flatten()\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values')\n",
        "plt.ylabel('Predictions')\n",
        "lims = [0, 2]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNU1oTBMGep8"
      },
      "source": [
        "# error = test_predictions - Cl_test_labels\n",
        "# plt.hist(error, bins=25)\n",
        "# plt.xlabel('Prediction Error')\n",
        "# _ = plt.ylabel('Count')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTPIBBDQGiHO"
      },
      "source": [
        "dnn_model_3.save('dnn_model_3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlYghSf3GlPa"
      },
      "source": [
        "#reloaded = tf.keras.models.load_model('dnn_model_3')\n",
        "\n",
        "\n",
        "test_results['Model 3'] = dnn_model_3.evaluate(test_features, test_labels, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul_Y9A3LGoPK"
      },
      "source": [
        "pd.DataFrame(test_results, index=['RMSE']).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag74I6L8nX86"
      },
      "source": [
        "#**Model 4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ez4i8zMe5i8"
      },
      "source": [
        "def model_4(norm):\n",
        "  model = keras.Sequential([\n",
        "      norm,\n",
        "\n",
        "\n",
        "      layers.Dense(128, activation='relu'),\n",
        "      layers.Dense(128, activation='relu'),\n",
        "      layers.Dense(128, activation='relu'),\n",
        "      layers.Dense(256, activation='relu'),\n",
        "\n",
        "      layers.Dense(256, activation='relu'),\n",
        "\n",
        "      layers.Dense(256, activation='relu'),\n",
        "\n",
        "      layers.Dense(1)])\n",
        "\n",
        "  # model.compile(loss='mean_squared_error',\n",
        "  #               optimizer=tf.keras.optimizers.Adam(0.001))\n",
        "  \n",
        "  model.compile(optimizer = \"rmsprop\", loss = root_mean_squared_error)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb96dyfKnj4c"
      },
      "source": [
        "#dnn_model = build_and_compile_model(normalizer)\n",
        "\n",
        "dnn_model_4 = model_4(normalizer)\n",
        "dnn_model_4.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV65EmpDnnrp"
      },
      "source": [
        "%%time\n",
        "history = dnn_model_4.fit(\n",
        "    train_features, train_labels,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[PlotLossesKeras()],\n",
        "    verbose=1, epochs=300, batch_size = 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hs_qhGwnxLc"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.ylim([0, 0.3])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('RMSE')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WSMmEMBn0dX"
      },
      "source": [
        "loss_df = pd.DataFrame(history.history[\"loss\"])\n",
        "loss_df.columns =['Model 4']\n",
        "loss_df.to_excel('Model_4.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70xBx9octIog"
      },
      "source": [
        "val_loss_df = pd.DataFrame(history.history[\"val_loss\"])\n",
        "val_loss_df.columns =['Model 4']\n",
        "val_loss_df.to_excel('val_Model_4.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exmF3lgjn6S0"
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3uVcfU1n-Vj"
      },
      "source": [
        "test_predictions = dnn_model_4.predict(test_features).flatten()\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values')\n",
        "plt.ylabel('Predictions')\n",
        "lims = [0, 2]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6Q1KdXOoCJ_"
      },
      "source": [
        "# error = test_predictions - Cl_test_labels\n",
        "# plt.hist(error, bins=25)\n",
        "# plt.xlabel('Prediction Error')\n",
        "# _ = plt.ylabel('Count')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT0w6Z6VoFpS"
      },
      "source": [
        "dnn_model_4.save('dnn_model_4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsKJ95XwoJrD"
      },
      "source": [
        "#reloaded = tf.keras.models.load_model('dnn_model_4')\n",
        "\n",
        "\n",
        "test_results['Model 4'] = dnn_model_4.evaluate(test_features, test_labels, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qolVNOCQoMmi"
      },
      "source": [
        "pd.DataFrame(test_results, index=['RMSE']).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJDqyRJ_Cy1k"
      },
      "source": [
        "#**Model 5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMDx2r5FC4OJ"
      },
      "source": [
        "def model_5(norm):\n",
        "  model = keras.Sequential([\n",
        "      norm,\n",
        "      layers.Dense(256, activation='relu'),\n",
        "\n",
        "      layers.Dense(256, activation='relu'),\n",
        "\n",
        "      layers.Dense(256, activation='relu'),\n",
        "\n",
        "      layers.Dense(256, activation='relu'),\n",
        "      layers.Dense(256, activation='relu'),\n",
        "      # layers.Dense(128, activation='relu'),\n",
        "\n",
        "      layers.Dense(1)])\n",
        "\n",
        "  # model.compile(loss='mean_squared_error',\n",
        "  #               optimizer=tf.keras.optimizers.Adam(0.001))\n",
        "  \n",
        "  model.compile(optimizer = \"rmsprop\", loss = root_mean_squared_error)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAhb3vpIC84e"
      },
      "source": [
        "#dnn_model = build_and_compile_model(normalizer)\n",
        "\n",
        "dnn_model_5 = model_5(normalizer)\n",
        "dnn_model_5.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFvXBiMwDA0a"
      },
      "source": [
        "%%time\n",
        "history = dnn_model_5.fit(\n",
        "    train_features, train_labels,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[PlotLossesKeras()],\n",
        "    verbose=1, epochs=300, batch_size = 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP_DdIcwDLp5"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.ylim([0, 0.3])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('RMSE')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7ConB4_DPiJ"
      },
      "source": [
        "loss_df = pd.DataFrame(history.history[\"loss\"])\n",
        "loss_df.columns =['Model 5']\n",
        "loss_df.to_excel('Model_5.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMKnUkhwtMxG"
      },
      "source": [
        "val_loss_df = pd.DataFrame(history.history[\"val_loss\"])\n",
        "val_loss_df.columns =['Model 5']\n",
        "val_loss_df.to_excel('val_Model_5.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIcuq2VMDVBf"
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtxl2PPxDYkN"
      },
      "source": [
        "test_predictions = dnn_model_5.predict(test_features).flatten()\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values')\n",
        "plt.ylabel('Predictions')\n",
        "lims = [0, 2]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyXMvVgUDb2m"
      },
      "source": [
        "# error = test_predictions - Cl_test_labels\n",
        "# plt.hist(error, bins=25)\n",
        "# plt.xlabel('Prediction Error')\n",
        "# _ = plt.ylabel('Count')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t92qKgFTDfUB"
      },
      "source": [
        "dnn_model_5.save('dnn_model_5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSZJdtaQDilv"
      },
      "source": [
        "#reloaded = tf.keras.models.load_model('dnn_model_5')\n",
        "\n",
        "\n",
        "test_results['Model 5'] = dnn_model_5.evaluate(test_features, test_labels, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm06e19PDl62"
      },
      "source": [
        "pd.DataFrame(test_results, index=['RMSE']).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuXlXIf2MjvF"
      },
      "source": [
        "#**Loss DataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW__IZtoMpVu"
      },
      "source": [
        "d1 = pd.read_excel('/content/Model_1.xlsx', index_col = 0)\n",
        "d2 = pd.read_excel('/content/Model_2.xlsx', index_col = 0)\n",
        "d3 = pd.read_excel('/content/Model_3.xlsx', index_col = 0)\n",
        "d4 = pd.read_excel('/content/Model_4.xlsx', index_col = 0)\n",
        "d5 = pd.read_excel('/content/Model_5.xlsx', index_col = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDsatCL2NRPg"
      },
      "source": [
        "l = pd.concat([d1, d2, d3, d4, d5],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-_mv2kPNadg"
      },
      "source": [
        "l.to_excel(\"loss.xls\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0J3_sf6tRvM"
      },
      "source": [
        "d1 = pd.read_excel('/content/val_Model_1.xlsx', index_col = 0)\n",
        "d2 = pd.read_excel('/content/val_Model_2.xlsx', index_col = 0)\n",
        "d3 = pd.read_excel('/content/val_Model_3.xlsx', index_col = 0)\n",
        "d4 = pd.read_excel('/content/val_Model_4.xlsx', index_col = 0)\n",
        "d5 = pd.read_excel('/content/val_Model_5.xlsx', index_col = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L2E0BmmtYrD"
      },
      "source": [
        "l = pd.concat([d1, d2, d3, d4, d5],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb_L6ixYtaIU"
      },
      "source": [
        "l.to_excel(\"val_loss.xls\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgGQuV-yqYZH"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQXbKXb0ataw"
      },
      "source": [
        "exp = pd.read_excel('/content/pca_16k.xlsx')\n",
        "exp.head(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djO3qgWyaxcT"
      },
      "source": [
        "#test_predictions = dnn_model_1.predict(exp.iloc[:,0:2]).flatten()\n",
        "test_predictions = dnn_model_5.predict(exp.iloc[:,0:4])\n",
        "test_predictions\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(exp.iloc[:,4], test_predictions)\n",
        "plt.xlabel('True Values')\n",
        "plt.ylabel('Predictions')\n",
        "lims = [0.08, 1.1]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)\n",
        "dnn_model_5.evaluate(exp.iloc[:,0:4], exp.iloc[:,4], verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rag_jYlbXE2"
      },
      "source": [
        "predcl = pd.DataFrame(test_predictions)\n",
        "predcl.head()\n",
        "adding = exp.iloc[:,0:4]\n",
        "adding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EjEFvETGkvG"
      },
      "source": [
        "adding['pred_cl'] = predcl.iloc[:,0:3].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjwHPleUICDW"
      },
      "source": [
        "adding.head(16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzfW4vEDJyWe"
      },
      "source": [
        "# adding['abs_cl'] = adding.apply(\n",
        "#     lambda row: abs(row.actual_cl - row.pred_cl), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaRK3UjdMBka"
      },
      "source": [
        "# adding['abs_cd'] = adding.apply(\n",
        "#     lambda row: abs(row.CD - row.pred_cd), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WDhri9ENjOu"
      },
      "source": [
        "# adding_sorted_cl= adding.sort_values(['abs_cl'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klHCeqUANsf4"
      },
      "source": [
        "#adding_sorted_cl.drop(['pred_cd', 'abs_cl','abs_cd'], axis=1, inplace=True)\n",
        "# adding_sorted_cl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBayXk8ASJ0a"
      },
      "source": [
        "# adding_sorted_cd= adding.sort_values(['abs_cd'])\n",
        "# adding_sorted_cd.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McpMbYPWoY89"
      },
      "source": [
        "adding.to_excel('ml_cl_model2.xls')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CMM3w6iEOcz"
      },
      "source": [
        "NACA - 0012"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6sfsLosKvGg"
      },
      "source": [
        "plt.scatter(adding.iloc[0:16,2], adding.iloc[0:16,3])\n",
        "plt.scatter(adding.iloc[0:16,2], adding.iloc[0:16,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpUI8WMUEV_a"
      },
      "source": [
        "NACA - 0015"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4-fwLCZMlLX"
      },
      "source": [
        "plt.scatter(adding.iloc[17:32,2], adding.iloc[17:32,3])\n",
        "plt.scatter(adding.iloc[17:32,2], adding.iloc[17:32,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unXK-2lY-Nho"
      },
      "source": [
        "NACA - 0018"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkga99QEEdvv"
      },
      "source": [
        "plt.scatter(adding.iloc[33:49,2], adding.iloc[33:49,3])\n",
        "plt.scatter(adding.iloc[33:49,2], adding.iloc[33:49,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "txhgJoegk-YK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}